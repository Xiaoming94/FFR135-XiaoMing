\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}

\title{All Code Used during HW1}

\begin{document}
\maketitle

\begin{verbatim}
# hopfieldnetwork.py
# author: Henry Yang (940503-1056)

import numpy as np
import random

###############################################
# Class for the Hopfield Model Neural Network #
# Using McCulloch Pitts Neurons               #
###############################################

def genRandPatterns(patterns,bitts):
    pat = np.random.randint(2,size=(patterns,bitts)) * 2 - 1
    return pat

def calcWeights(patterns):
    (_,bitts) = patterns.shape 
    w = np.zeros((bitts,bitts))
    for p in patterns :
        vecP = p.reshape(bitts,1)
        w = w + vecP @ np.transpose(vecP)


    return 1/bitts * w


class HopField(object):
    def __init__(self,usedata=False,data=None,patterns=10,bitts=5):
        # Generating Patterns
        if not usedata :
            pat = genRandPatterns(patterns,bitts)

        else :
            pat = data

        # Storing The Patterns
        self.patterns = pat

        # Storing the weights
        self.weights = calcWeights(pat)

    # Asynchronus feed Update
    def feedAsync(self,input,neuronIndex):
        #(bitts,_) = self.weights.shape
        #neuronIndex = np.random.randint(low=0,high=bitts)
        neuronWeights = self.weights[neuronIndex,:]
        z = neuronWeights @ input
        neuronState = np.sign(z)
        if neuronState == 0:
            neuronState = 1
        return neuronState
    
    # Synchronous feed.
    # Implemented as a matrix multiplication
    def feedSync(self,input):
        z_vec = self.weights @ input
        neuronStates = np.sign(z_vec)
        neuronStates[np.where(neuronStates == 0)] = 1
        return neuronStates

        
# stochastichopfield.py
# Author: Henry Yang

import numpy as np
import random
from hopfieldnetwork import HopField

#######################################################
# Class declaration for the Stochastic Hopfield Model #
# As based on the lecture note.                       #
# Implemented as a subclass of HopField               #
#######################################################

class StochasticHopfield(HopField):

    # Overriding the constructor to add a beta variable
    def __init__(self,usedata=False,data=None,patterns=10,bitts=5,beta=1):
        super(StochasticHopfield, self).__init__(usedata,data,patterns,bitts)
        self.beta = beta
    
    # Definition of gFunction according to lecture slides
    def gFunction(self,b):
        nat_e = np.exp(-2 * self.beta * b)
        return 1/(1 + nat_e)

    # Asynchronous feed using Stochastic dynamics
    def feedAsync(self,input,neuronIndex):
        neuronWeights = self.weights[neuronIndex,:]
        b = neuronWeights @ input
        g = self.gFunction(b)
        r = random.random()
        return 1 if r < g else -1
    
# problem1b.py
# Author: Henry Yang (940503-1056)

import numpy as np
from hopfieldnetwork import HopField

#########################################################
# This is the source file for solving the first second  #
# part of problem 1 in Assignment1 of FFR135            #
# The parameters chosen are given by the Assignnment    #
#########################################################

patterns = [12,20,40,60,80,100]
trials = 10 ** 5
bitts = 100
p_errors_list = []

for p in patterns :
    errors = 0
    for i in range(trials):
        net = HopField(patterns=p,bitts=bitts)
          
        # Randomly chooose a pattern and which neuron to observe
        n_i = np.random.randint(bitts)
        p_i = np.random.randint(p)
        inputPattern = net.patterns[p_i]
        
        neuronState = net.feedAsync(inputPattern,n_i)
        if(neuronState != inputPattern[n_i]):
            errors += 1
    
    p_error = errors/trials
    print("p_error : %s , for %s patterns" % (p_error,p))

    p_errors_list.append(p_error)

print(p_errors_list)

        
# problem1.py
# Author: Henry Yang(940503-1056)

import numpy as np
from hopfieldnetwork import HopField

#########################################################
# This is the source file for solving the first part of #
# problem 1 in Assignment1 of FFR135                    #
# The parameters chosen are given by the Assignnment    #
#########################################################

##
# Setting Parameters
patterns = [12,20,40,60,80,100] # Pattern counts to test
trials = 10 ** 5    # Number of Independent trials
bitts = 100         # Number of bitts in each pattern
p_errors_list = []

# Performing the simulation

for p in patterns :
    errors = 0
    for i in range(trials):
        net = HopField(patterns=p,bitts=bitts)

        # Set Diagonal to Zeroes
        for i in range(bitts):
            net.weights[i,i] = 0

        # Randomly chooose a pattern and which neuron to observe
        n_i = np.random.randint(bitts)
        p_i = np.random.randint(p)
        inputPattern = net.patterns[p_i]
        
        # Feed the pattern and check the results
        # Feeding the pattern using asynchronous update
        neuronState = net.feedAsync(inputPattern,n_i)
        if(neuronState != inputPattern[n_i]):
            errors += 1
    
    p_error = errors/trials
    print("p_error : %s , for %s patterns" % (p_error,p))

    p_errors_list.append(p_error)

print(p_errors_list)

        
# problem2.py
# Author: Henry Yang

import numpy as np
from hopfieldnetwork import HopField
import random as r

############################################
# Script file for all of problem 2         #
# As according to the problem description  #
# Given on OpenTA                          #
############################################

###
# Function for updating the update pattern
# Implemented using the "Typewriter" schema described in the problem description
def feedUpdateConverge(net,input):
    states = input
    converged = False
    bitts = input.size
    while not converged:
        oldStates = states.copy()
        for i in range(bitts):
            states[i] = net.feedAsync(states,i)
        
        diff = np.sum(states - oldStates)
        converged = diff == 0
    
    return states

###
# Function for finding a matching stored pattern 
# for a particular bit pattern
# returns 6 if pattern doesn't match any stored once

def findMatched(states,inputs):
    i = 1
    for p in inputs :
        if np.sum(p - states) == 0:
            return i
        elif np.sum(p + states) == 0:
            return -i
        i += 1
    return i 
        
# Following arrays (vectors) are the training data
# Binary with 1 and -1
# Pattern takes the form of 0,1,2,3, & 4

x1=np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, 1, 1, 1, 1, 1, 1, -1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, 1, 1, 1, -1, -1, 1, 1, 1, -1,
             -1, -1, 1, 1, 1, 1, 1, 1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
            ])
x2=np.array([
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1,
             -1, -1, -1, 1, 1, 1, 1, -1, -1, -1 ])

x3=np.array([
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1,
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, 1, 1, 1, -1, -1,
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1,
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1,
     1, 1, 1, -1, -1, -1, -1, -1, -1, -1,
     1, 1, 1, -1, -1, -1, -1, -1, -1, -1,
     1, 1, 1, -1, -1, -1, -1, -1, -1, -1,
     1, 1, 1, -1, -1, -1, -1, -1, -1, -1,
     1, 1, 1, -1, -1, -1, -1, -1, -1, -1,
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1,
     1, 1, 1, 1, 1, 1, 1, 1, -1, -1 ])

x4=np.array([
     -1, -1, 1, 1, 1, 1, 1, 1, -1, -1,
     -1, -1, 1, 1, 1, 1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, 1, 1, 1, 1, 1, 1, -1, -1,
     -1, -1, 1, 1, 1, 1, 1, 1, -1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, 1, 1, 1, -1,
     -1, -1, 1, 1, 1, 1, 1, 1, 1, -1,
     -1, -1, 1, 1, 1, 1, 1, 1, -1, -1
    ])

x5=np.array([
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
     -1, 1, 1, 1, 1, 1, 1, 1, 1, -1,
     -1, 1, 1, 1, 1, 1, 1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
     -1, -1, -1, -1, -1, -1, -1, 1, 1, -1 ])

data = np.stack((x1,x2,x3,x4,x5))

# Given input patterns
# These are later fed to the network

input1 = np.array([
    1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 
    1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 
    -1, -1, -1, -1, -1, -1, -1, -1, 1, 1]) 

input2 = np.array([[1, 1, -1, -1, -1, -1, -1, -1, 1, 1], [1, 1, -1, -1, -1, -1, -1, -1, -1, 1], [1, 1, 1, 1, 1, 1, -1, -1, -1, 1], [1, 1, 1, 1, 1, 1, -1, -1, -1, 1], [1, 1, 1, 1, 1, 1, -1, -1, -1, 1], [1, 1, 1, 1, 1, 1, -1, -1, -1, 1], [1, 1, 1, 1, 1, 1, -1, -1, -1, 1], [1, 1, -1, -1, -1, -1, -1, -1, 1, 1], [1, 1, -1, -1, -1, 1, 1, 1, -1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1], [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1], [-1, -1, 1, 1, 1, 1, 1, 1, 1, -1], [-1, -1, 1, 1, 1, 1, 1, 1, -1, -1]] ).flatten()

input3 = np.array([
    1, -1, -1, 1, 1, 1, 1, -1, -1, 1,
    1, -1, -1, 1, 1, 1, 1, -1, -1, 1,
    -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
    -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
    -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
    -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
    -1, 1, 1, -1, -1, -1, -1, 1, 1, -1,
    -1, 1, 1, 1, 1, 1, 1, 1, 1, -1,
    -1, 1, 1, 1, 1, 1, 1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1,
    -1, -1, -1, -1, -1, -1, -1, 1, 1, -1]
)

inputs = [input1,input2,input3]

# Constructing the network

net = HopField(True,data)

# Setting diagonal to 0

for i in range(x1.size):
    net.weights[i,i] = 0

# Performing the experiments

for i in inputs :
    print(i.reshape(16,10))
    res = feedUpdateConverge(net,i)
    print("current input converges to:")
    print(res.reshape(16,10))
    pat = findMatched(res,data)
    print("Matching pattern : %s" % pat)

    print()
# problem3.py
# Author: Henry Yang

import numpy as np
from stochastichopfield import StochasticHopfield

########################################
# Script file for problem 3            #
# Using a stochastic Hopfield model    #
# Calculating the orderparameter       #
# With the two given set of parameters #
########################################

## Given parameters
experiments = 100
bigT = 10 ** 5
bigN = 200
beta = 2
patterns = [5,40]

# Performing the experiments
# Calculates the average order parameter using cumulated sums
# Than dividing with numbers of experiments

for p in patterns:

    # Declaraing the cumulative sum
    orderParam = 0
    for _ in range(experiments):
        net = StochasticHopfield(patterns = p, bitts = bigN, beta = beta)
        for i in range(bigN):
            net.weights[i,i] = 0

        # Inner orderparameters
        m = 0

        # Choosing the random neurons
        randIndices = np.random.randint(200,size=bigT)
        
        # Picking the first pattern
        x1 = net.patterns[0]
        states = x1.copy()

        # Calculating the order parameters
        for i in randIndices :
            new_si = net.feedAsync(states,i)
            states[i] = new_si
            m = m + (states @ x1)/bigN

        orderParam += m/bigT

    # Printing the results    
    print("Order parameter for p = %s : %s" % (p,orderParam/experiments))

\end{verbatim}
\end{document}